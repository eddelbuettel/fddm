---
title: "Validity of Methods"
author: "Kendal Foster"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
bibliography: references.bib
output:
  rmarkdown::html_vignette:
    css: stile.css
    toc: true
    toc_depth: 2
vignette: >
  %\VignetteIndexEntry{Validity of Methods}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  error = TRUE, # ensures compilation even if testthat checks fail
  comment = "#>"
)
```






From the `fddm` package, `dfddm` evaluates the density function (or probability density function, PDF) for the Ratcliff diffusion decision model (DDM) with following parameters: $a \in (0, \infty)$ (threshold separation), $v \in (-\infty, \infty)$ (drift rate), $t_0 \in [0, \infty)$ (non-decision time/response time constant), $w \in (0, 1)$ (relative starting point), and $sv \in (0, \infty)$ (inter-trial-variability of drift).
<br><br>





# Background {#background}
<hr class="sec1">

This vignette is more techincal in nature and will demonstrate not only the consistency across our implementations but also in accordance with the other state-of-the-art algorithms in the current literature. First we perform a simple test in [Validating the Density Functions](#den), evaluating each algorithm for the density function of the DDM and comparing their consistency. To ensure rigorous concordance across all algorithms, we test each algorithm throughout a sufficiently large and granular parameter space that can be found fully defined in the subsection [Generating Data](#den-gen). Of course these algorithms are approximations, and as such they will provide slightly different results given the same parameter inputs. To ensure that these small differences in density output do not affect the results of fitting parameters to real-world data, we also include testing in an optimization setting in [Validating Fitting (Optimization) Using the Density Functions](#fit). We use the various algorithms as the bases for loglikelihood functions for the optimization process and include a variety of starting points in the parameter space to ensure rigorous consistency testing.





# Validating the Density Functions {#den}
<hr class="sec1">

It is imperative to show that our density functions produce the same results as the current standards. To demonstrate this, we calculate the lower probability density for a granular parameter space and show that all of the results are within an acceptable error tolerance. We only calculate the lower probability density because the upper probability density negates $v$ ($v' = v$) and takes the complement of $w$ ($w' = 1-w$); our parameter space already includes all of these values so calculating the upper probability density would be redundant. The fully defined parameter space can be found in the code chunk in the [following subsection](#den-gen), and it includes both realistically feasible values and some extreme values for each parameter. Since each of these functions approximates an infinite summation to a desired precision of $\epsilon$, we allow for a difference of $2 \cdot \epsilon$ between any pair of calculated densities to account for convergence from above and below the limit of the summation. (would a little picture description help here?).



## Generating Data {#den-gen}

First we load the necessary packages and code available from the current literature.
```{r validity-pkg, eval=TRUE}
library("fddm")
library("rtdists")
library("RWiener")
source(system.file("extdata", "Kesselmeier_density.R", package = "fddm", mustWork = TRUE))
```

The following code chunk stores the lower probability densities calculated across the parameter space using the different methods; we also calculate and store the log-probability for consistency testing.
```{r validity-run, eval=TRUE}
# Define parameter space
RT <- c(0.001, 0.1, 1, 2, 3, 4, 5, 10, 30)
A <- c(0.25, 0.5, 1, 2.5, 5)
V <- c(-5, -2, 0, 2, 5)
t0 <- 1e-4 # must be nonzero for RWiener
W <- c(0.2, 0.5, 0.8)
SV <- c(0, 0.5, 1, 1.5)
SV_THRESH <- 0.05
eps <- 1e-6 # this is the setting from rtdists

nRT <- length(RT)
nA <- length(A)
nV <- length(V)
nW <- length(W)
nSV <- length(SV)
resp0 <- rep(0, nRT)
rresp0 <- rep("lower", nRT)

fnames <- c("fs_Fos_17", "fs_Fos_14",
            "fs_Kes_17", "fs_Kes_14", "fs_Nav_17", "fs_Nav_14",
            "fb_Kes_17", "fb_Kes_14", "fb_Nav_17", "fb_Nav_14",
            "fl_Nav_09", "RWiener", "Kesselmeier", "rtdists")
nf <- length(fnames)

res <- data.frame(matrix(ncol = 9, nrow = nf*nRT*nA*nV*nW*nSV))
colnames(res) <- c('rt', 'a', 'v', 'w', 'sv', 'FuncName', 'res', 'dif',
                   'log_res')
start <- 1
stop <- nf

# Loop through each combination of parameters and record results
for (rt in 1:nRT) {
  for (a in 1:nA) {
    for (v in 1:nV) {
      for (w in 1:nW) {
        for (sv in 1:nSV) {
          # add the rt, v, a, w, and function names to the dataframe
          res[start:stop, 1] <- rep(RT[rt], nf)
          res[start:stop, 2] <- rep(A[a]  , nf)
          res[start:stop, 3] <- rep(V[v]  , nf)
          res[start:stop, 4] <- rep(W[w]  , nf)
          res[start:stop, 5] <- rep(SV[sv], nf)
          res[start:stop, 6] <- fnames

          # calculate "lower" density
          res[start,    7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Foster",
                                    summation_small = "2017", scale = "small",
                                    err_tol = eps)
          res[start+1,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Foster",
                                    summation_small = "2014", scale = "small",
                                    err_tol = eps)
          res[start+2,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Kesselmeier",
                                    summation_small = "2017", scale = "small",
                                    err_tol = eps)
          res[start+3,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Kesselmeier",
                                    summation_small = "2014", scale = "small",
                                    err_tol = eps)
          res[start+4,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Navarro",
                                    summation_small = "2017", scale = "small",
                                    err_tol = eps)
          res[start+5,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Navarro",
                                    summation_small = "2014", scale = "small",
                                    err_tol = eps)
          res[start+6,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Kesselmeier",
                                    summation_small = "2017", scale = "both",
                                    err_tol = eps)
          res[start+7,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Kesselmeier",
                                    summation_small = "2014", scale = "both",
                                    err_tol = eps)
          res[start+8,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Navarro",
                                    summation_small = "2017", scale = "both",
                                    err_tol = eps)
          res[start+9,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "Navarro",
                                    summation_small = "2014", scale = "both",
                                    err_tol = eps)
          res[start+10,  7] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = FALSE, n_terms_small = "",
                                    summation_small = "", scale = "large",
                                    err_tol = eps)
          res[start+11, 7] <- dwiener(RT[rt], resp = rresp0[rt], alpha = A[a],
                                      delta = V[v], tau = t0, beta = W[w],
                                      give_log = FALSE)
          res[start+12, 7] <- fs14_R(t = RT[rt]-t0, a = A[a], v = V[v],
                                     w = W[w], eps = eps)
          res[start+13, 7] <- ddiffusion(RT[rt], rresp0[rt], a = A[a], v = V[v],
                                        t0 = t0, z = W[w]*A[a], sv = SV[sv])
          if (sv > SV_THRESH) { # multiply to get density with sv
            t <- RT[rt] - t0
            M <- exp(V[v] * A[a] * W[w] + V[v]*V[v] * t / 2 +
                     (SV[sv]*SV[sv] * A[a]*A[a] * W[w]*W[w] -
                       2 * V[v] * A[a] * W[w] - V[v]*V[v] * t) /
                     (2 + 2 * SV[sv]*SV[sv] * t)) / sqrt(1 + SV[sv]*SV[sv] * t)
            res[start+11, 7] <- M * res[start+11, 7] # RWiener
            res[start+12, 7] <- M * res[start+12, 7] # Kesselmeier_R
          }

          # calculate differences
          ans <- res[start, 7] # use Foster_2017_small as truth
          res[start,    8] <- abs(res[start,    7] - ans)
          res[start+1,  8] <- abs(res[start+1,  7] - ans)
          res[start+2,  8] <- abs(res[start+2,  7] - ans)
          res[start+3,  8] <- abs(res[start+3,  7] - ans)
          res[start+4,  8] <- abs(res[start+4,  7] - ans)
          res[start+5,  8] <- abs(res[start+1,  7] - ans)
          res[start+6,  8] <- abs(res[start+6,  7] - ans)
          res[start+7,  8] <- abs(res[start+7,  7] - ans)
          res[start+8,  8] <- abs(res[start+8,  7] - ans)
          res[start+9,  8] <- abs(res[start+9,  7] - ans)
          res[start+10, 8] <- abs(res[start+10, 7] - ans)
          res[start+11, 8] <- abs(res[start+11, 7] - ans)
          res[start+12, 8] <- abs(res[start+12, 7] - ans)
          res[start+13, 8] <- abs(res[start+13, 7] - ans)

          # calculate log of "lower" density
          res[start,    9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Foster",
                                    summation_small = "2017", scale = "small",
                                    err_tol = eps)
          res[start+1,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Foster",
                                    summation_small = "2014", scale = "small",
                                    err_tol = eps)
          res[start+2,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Kesselmeier",
                                    summation_small = "2017", scale = "small",
                                    err_tol = eps)
          res[start+3,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Kesselmeier",
                                    summation_small = "2014", scale = "small",
                                    err_tol = eps)
          res[start+4,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Navarro",
                                    summation_small = "2017", scale = "small",
                                    err_tol = eps)
          res[start+5,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Navarro",
                                    summation_small = "2014", scale = "small",
                                    err_tol = eps)
          res[start+6,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Kesselmeier",
                                    summation_small = "2017", scale = "both",
                                    err_tol = eps)
          res[start+7,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Kesselmeier",
                                    summation_small = "2014", scale = "both",
                                    err_tol = eps)
          res[start+8,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Navarro",
                                    summation_small = "2017", scale = "both",
                                    err_tol = eps)
          res[start+9,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "Navarro",
                                    summation_small = "2014", scale = "both",
                                    err_tol = eps)
          res[start+10,  9] <- dfddm(rt = RT[rt], response = resp0[rt], a = A[a],
                                    v = V[v], t0 = t0, w = W[w], sv = SV[sv],
                                    log = TRUE, n_terms_small = "",
                                    summation_small = "", scale = "large",
                                    err_tol = eps)
          res[start+11, 9] <- dwiener(RT[rt], resp = rresp0[rt], alpha = A[a],
                                      delta = V[v], tau = t0, beta = W[w],
                                      give_log = TRUE)
          res[start+12, 9] <- log(fs14_R(t = RT[rt]-t0, a = A[a], v = V[v],
                                         w = W[w], eps = eps))
          res[start+13, 9] <- log(ddiffusion(RT[rt], rresp0[rt], a = A[a],
                                             v = V[v], t0 = t0, z = W[w]*A[a],
                                             sv = SV[sv]))
          if (sv > SV_THRESH) { # add to get log of density with sv
            t <- RT[rt] - t0
            M <- V[v] * A[a] * W[w] + V[v]*V[v] * t / 2 +
                 (SV[sv]*SV[sv] * A[a]*A[a] * W[w]*W[w] -
                  2 * V[v] * A[a] * W[w] - V[v]*V[v] * t) /
                 (2 + 2 * SV[sv]*SV[sv] * t) - 0.5 * log(1 + SV[sv]*SV[sv] * t)
            res[start+11, 9] <- M + res[start+11, 9] # RWiener
            res[start+12, 9] <- M + res[start+12, 9] # Kesselmeier_R
          }

          # iterate start and stop values
          start = start + nf
          stop = stop + nf
        }
      }
    }
  }
}
```



## Testing the Density Functions {#den-test}

Now we test the consistency of the various density function approximations by using the `testthat` package. As [discussed above](#den), we allow the difference between any two outputs to be twice the original desired accuracy to allow for convergence from either above or below. We have to amend some of the checks because of the instability of some of the methods, and these are documented in the [Known Errors](#den-ke) section below. First we check that all of the approximations produce densities that are non-negative (we allow a density equal to zero). Next, we check the consistency of the internal `dfddm` methods before confirming their accuracy with external code from established packages. Lastly, we run similar tests to check the consistency of the logged results. If all tests pass correctly, there should be no output.
```{r validity-test, eval=TRUE}
library("testthat")

# Subset results
Foster <- subset(res, FuncName %in% fnames[c(1,2)])
Kesselmeier_s <- subset(res, FuncName %in% fnames[c(3,4)])
Kesselmeier_b <- subset(res, FuncName %in% fnames[c(7,8)])
Navarro_s <- subset(res, FuncName %in% fnames[c(5,6)])
Navarro_l <- subset(res, FuncName %in% fnames[11])
Navarro_b <- subset(res, FuncName %in% fnames[c(9,10)])
rtdists <- subset(res, FuncName == "rtdists")
RWiener <- subset(res, FuncName == "RWiener")
Kesselmeier_R <- subset(res, FuncName == "Kesselmeier")

# Subset results
Foster <- subset(res, FuncName %in% fnames[c(1,2)])
Kesselmeier_s <- subset(res, FuncName %in% fnames[c(3,4)])
Kesselmeier_b <- subset(res, FuncName %in% fnames[c(7,8)])
Navarro_s <- subset(res, FuncName %in% fnames[c(5,6)])
Navarro_l <- subset(res, FuncName %in% fnames[11])
Navarro_b <- subset(res, FuncName %in% fnames[c(9,10)])
rtdists <- subset(res, FuncName == "rtdists")
RWiener <- subset(res, FuncName == "RWiener")
Kesselmeier_R <- subset(res, FuncName == "Kesselmeier")

# Compensate for KE 1, 2
Nav_s_res_0 <- subset(Navarro_s, res < 0) # KE 2
Nav_s_0 <- min(Nav_s_res_0$rt / Nav_s_res_0$a / Nav_s_res_0$a) # = 10
Nav_l_res_0 <- subset(Navarro_l, res < 0) # KE 3
Nav_l_0 <- max(Nav_l_res_0$rt / Nav_l_res_0$a / Nav_l_res_0$a) # = 0.04
Nav_l_dif_2eps <- subset(Navarro_l, dif > 2*eps) # KE 3
Nav_l_2 <- max(Nav_l_dif_2eps$rt / Nav_l_dif_2eps$a / Nav_l_dif_2eps$a) # = 0.004


# Ensure all densities are non-negative
test_that("Non-negativity of densities", {
  expect_true(all(Foster$res >= 0))
  expect_true(all(Kesselmeier_s$res >= 0))
  expect_true(all(Kesselmeier_b$res >= 0))
  expect_true(all(subset(Navarro_s, rt/a/a < Nav_s_0)$res >= 0)) # see KE 1
  expect_true(all(subset(Navarro_l, rt/a/a > Nav_l_0)$res >= 0)) # see KE 2
  expect_true(all(subset(Navarro_b, rt/a/a > Nav_l_0)$res >= 0)) # see KE 3
  expect_true(all(rtdists$res >= 0))
  expect_true(all(RWiener$res >= 0))
  expect_true(all(Kesselmeier_R$res >= 0))
})

# Test accuracy within 2*eps (allows for convergence from above and below)
test_that("Consistency among internal methods", {
  expect_true(all(Foster$dif < 2*eps))
  expect_true(all(Kesselmeier_s$dif < 2*eps))
  expect_true(all(Kesselmeier_b$dif < 2*eps))
  expect_true(all(Navarro_s$dif < 2*eps)) # see KE 1
  expect_true(all(subset(Navarro_l, rt/a/a > Nav_l_2)$dif < 2*eps)) # see KE 2
  expect_true(all(Navarro_b$dif < 2*eps)) # see KE 1,2
})

test_that("Accuracy relative to established packages", {
  expect_true(all(rtdists$dif < 2*eps))
  expect_true(all(RWiener$dif < 2*eps))
  expect_true(all(subset(Kesselmeier_R, sv < SV_THRESH)$dif < 2*eps)) # see KE 4
})

test_that("Log-Consistency among internal methods", { # see KE 5
  expect_equal(subset(Foster, res > eps*eps)$log_res,
               log(subset(Foster, res > eps*eps)$res))
  expect_equal(subset(Kesselmeier_s, res > eps*eps)$log_res,
               log(subset(Kesselmeier_s, res > eps*eps)$res))
  expect_equal(subset(Kesselmeier_b, res > eps*eps)$log_res,
               log(subset(Kesselmeier_b, res > eps*eps)$res))
  expect_equal(subset(Navarro_s, res > eps*eps)$log_res,
               log(subset(Navarro_s, res > eps*eps)$res))
  expect_equal(subset(Navarro_l, res > eps*eps)$log_res,
               log(subset(Navarro_l, res > eps*eps)$res))
  expect_equal(subset(Navarro_b, res > eps*eps)$log_res,
               log(subset(Navarro_b, res > eps*eps)$res))
})

test_that("Log-Consistency of established packages", {
  expect_equal(subset(rtdists, res > eps*eps)$log_res,
               log(subset(rtdists, res > eps*eps)$res))
  expect_equal(subset(RWiener, res > eps*eps)$log_res,
               log(subset(RWiener, res > eps*eps)$res))
  expect_equal(subset(Kesselmeier_R, res > eps*eps)$log_res,
               log(subset(Kesselmeier_R, res > eps*eps)$res))
})
```



## Known Errors {#den-ke}

1) Navarro small-time approximation is unstable for "large" effective response times, $\frac{rt}{a^2} \leq 10$. It gives slightly negative densities for effective response times in this range. These parameter values should not have an effect on the "both" time scale because the large-time approximation should handle such locations in the parameter space. The negative results, however, are still within $2 \cdot \epsilon$ of the accepted results (basically zero).

2) Navarro large-time approximation is unstable for "small" effective response times, $\frac{rt}{a^2} \leq 0.06$. It gives slightly negative densities for effective response times in this range and gives inaccurate densities for effective response times of $\frac{rt}{a^2} \leq 0.009$. These parameter values should not have an effect on the "both" time scale because the small-time approximation should handle such locations in the parameter space.

3) The Navarro "both" time scale switches between the small-time and large-time approximations. This method relies too much on the unstable large time approximation, leading to its instability; thus we only need to subset to correct for the large time.

4) Kesselmeier_R approximation divides the error tolerance by the multiplicative term outside of the summation. Since the outside term is different when $sv > 0$, the approximation uses the incorrect error tolerance for $sv > 0$. This affects the number of terms required in the summation to achieve the desired precision, thus not actually achieving that desired precision. This issue is fixed in our implementation of the Kesselmeier method. For an example of this discrepancy, see the code below:
```{r known-errors, eval=FALSE}
rt <- 1.5
t <- rt - 1e-4
a <- 0.5
v <- 4.5
w <- 0.5
eps <- 1e-6
sv <- 0.9
sv0 <- exp(-v*a*w - v*v*t/2) / (a*a) # for constant drift rate
sv0_9 <- exp((-2*v*a*w - v*v*t + sv*sv*a*a*w*w)/(2 + 2*sv*sv*t)) /
         (a*a*sqrt(1+sv*sv*t)) # for variable drift rate
ks14_R(t/(a*a), w, eps/sv0) # = 2; the summation will only calculate 2 terms
ks14_R(t/(a*a), w, eps/sv0_9) # = 5; but the summation actually needs 5 terms
```





# Validating Fitting (Optimization) Using the Density Functions {#fit}
<hr class="sec1">

Perhaps the most practical use of `dfddm` is to use it in an optimization setting, such as fitting DDM parameters to real world data, and this section will show that all of the methods implemented in `dfddm` yield the same results in this setting. The parameters that we will fit are $a$ (threshold separation), $w$ (relative starting point), and $sv$ (inter-trial-variability of drift). Since the data contains a truthful classification for each trial, we also fit two different versions of $v$ (drift rate): $v_0$ for fitting to the truthful lower boundary, and $v_1$ for fitting to the truthful upper boundary. As many of the approximations in `dfddm` have different styles, we only test a subset of all the available methods in `dfddm` to avoid unnecessary testing.



## Generating the Parameter Estimates Using Real-World Data {#fit-gen}

We use a range of different starting values for the optimization function to ensure that none of the methods encounters a problem in the parameter space; however, we need to slightly restrict the starting values to prevent fitting issues with some of the small-time methods (see [Known Errors 5 and 6](#fit-ke)). We allow a difference of $0.0001$ across the methods for each combination of parameters since the density functions do return slightly different results (within $2 \cdot \epsilon$), as discussed in the previous section. The following subsections will define all of the functions used to generate the fittings and store the parameter estimates, provide the code to run the full fitting, and read the pre-fit data. Since running the full fitting for all of the individuals in the data takes a long time, we will forgo running the fitting and instead read pre-fitted parameter estimates.

First we load the necessary packages.
```{r fitting-pkg, eval=FALSE}
library("fddm")
library("rtdists")
```

### Log-Likelihood Functions {#fit-gen-llf}

This code chunk defines the log-likelihood functions used in the optimization algorithm. We only use a selection of the methods available in `dfddm` to avoid redundancy in our testing since most of the methods have multiple sibling approximations that are confirmed to be extremely similar. The log-likelihood functions are fairly straightforward and split the responses and associated response times by the truth to enable fitting distinct drift rates ($v_0$ for the lower density and $v_1$ for the upper density). In addition, the log-likelihood functions heavily penalize any approximations that return negative or otherwise invalid densities.
```{r loglik-fun, eval=FALSE}
ll_fs_Fos_17 <- function(pars, rt, resp, truth, err_tol) {
  rt1 <- rt[truth == 1]
  rt0 <- rt[truth == 0]
  resp1 <- resp[truth == 1]
  resp0 <- resp[truth == 0]

  # the truth is "upper" so use v1
  dens1 <- dfddm(rt = rt1, response = resp1, a = pars[[3]], v = pars[[1]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Foster", summation_small = "2017",
                 scale = "small", err_tol = err_tol)
  # the truth is "lower" so use v0
  dens0 <- dfddm(rt = rt0, response = resp0, a = pars[[3]], v = pars[[2]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Foster", summation_small = "2017",
                 scale = "small", err_tol = err_tol)

  densities <- c(dens1, dens0)
  if (any(densities <= 0)) return(1e6)
  return(-sum(log(densities)))
}

ll_fs_Kes_17 <- function(pars, rt, resp, truth, err_tol) {
  rt1 <- rt[truth == 1]
  rt0 <- rt[truth == 0]
  resp1 <- resp[truth == 1]
  resp0 <- resp[truth == 0]

  # the truth is "upper" so use v1
  dens1 <- dfddm(rt = rt1, response = resp1, a = pars[[3]], v = pars[[1]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Kesselmeier", summation_small = "2017",
                 scale = "small", err_tol = err_tol)
  # the truth is "lower" so use v0
  dens0 <- dfddm(rt = rt0, response = resp0, a = pars[[3]], v = pars[[2]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Kesselmeier", summation_small = "2017",
                 scale = "small", err_tol = err_tol)

  densities <- c(dens1, dens0)
  if (any(densities <= 0)) return(1e6)
  return(-sum(log(densities)))
}

ll_fs_Nav_17 <- function(pars, rt, resp, truth, err_tol) {
  rt1 <- rt[truth == 1]
  rt0 <- rt[truth == 0]
  resp1 <- resp[truth == 1]
  resp0 <- resp[truth == 0]

  # the truth is "upper" so use v1
  dens1 <- dfddm(rt = rt1, response = resp1, a = pars[[3]], v = pars[[1]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Navarro", summation_small = "2017",
                 scale = "small", err_tol = err_tol)
  # the truth is "lower" so use v0
  dens0 <- dfddm(rt = rt0, response = resp0, a = pars[[3]], v = pars[[2]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Navarro", summation_small = "2017",
                 scale = "small", err_tol = err_tol)

  densities <- c(dens1, dens0)
  if (any(densities <= 0)) return(1e6)
  return(-sum(log(densities)))
}

ll_fb_Kes_17 <- function(pars, rt, resp, truth, err_tol) {
  rt1 <- rt[truth == 1]
  rt0 <- rt[truth == 0]
  resp1 <- resp[truth == 1]
  resp0 <- resp[truth == 0]

  # the truth is "upper" so use v1
  dens1 <- dfddm(rt = rt1, response = resp1, a = pars[[3]], v = pars[[1]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Kesselmeier", summation_small = "2017",
                 scale = "both", err_tol = err_tol)
  # the truth is "lower" so use v0
  dens0 <- dfddm(rt = rt0, response = resp0, a = pars[[3]], v = pars[[2]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Kesselmeier", summation_small = "2017",
                 scale = "both", err_tol = err_tol)

  densities <- c(dens1, dens0)
  if (any(densities <= 0)) return(1e6)
  return(-sum(log(densities)))
}

ll_fb_Nav_17 <- function(pars, rt, resp, truth, err_tol) {
  rt1 <- rt[truth == 1]
  rt0 <- rt[truth == 0]
  resp1 <- resp[truth == 1]
  resp0 <- resp[truth == 0]

  # the truth is "upper" so use v1
  dens1 <- dfddm(rt = rt1, response = resp1, a = pars[[3]], v = pars[[1]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Navarro", summation_small = "2017",
                 scale = "both", err_tol = err_tol)
  # the truth is "lower" so use v0
  dens0 <- dfddm(rt = rt0, response = resp0, a = pars[[3]], v = pars[[2]],
                 t0 = pars[[4]], w = pars[[5]], sv = pars[[6]], log = FALSE,
                 n_terms_small = "Navarro", summation_small = "2017",
                 scale = "both", err_tol = err_tol)

  densities <- c(dens1, dens0)
  if (any(densities <= 0)) return(1e6)
  return(-sum(log(densities)))
}

ll_RTDists <- function(pars, rt, resp, truth) {
  rt1 <- rt[truth == 1]
  rt0 <- rt[truth == 0]
  resp1 <- resp[truth == 1]
  resp0 <- resp[truth == 0]

  # the truth is "upper" so use v1
  dens1 <- ddiffusion(rt1, resp1, a = pars[[3]], v = pars[[1]],
                      z = pars[[5]]*pars[[3]], t0 = pars[[4]], sv = pars[[6]])
  # the truth is "lower" so use v0
  dens0 <- ddiffusion(rt0, resp0, a = pars[[3]], v = pars[[2]],
                      z = pars[[5]]*pars[[3]], t0 = pars[[4]], sv = pars[[6]])

  densities <- c(dens1, dens0)
  if (any(densities <= 0)) return(1e6)
  return(-sum(log(densities)))
}
```



### Fitting Functions {#fit-gen-fun}

This code chunk defines the function that will run the optimization and produce the fitted parameter estimates for $v_1$, $v_0$, $a$, $w$, and $sv$. We include a variety of starting points to ensure that the optimization algorithm avoids reasonable local minima. As [discussed above](#fit), we must slightly restrict the starting values; this is exlained in [Known Errors](#fit-ke).
``` {r fitting-fun, eval=FALSE}
rt_fit <- function(data, id_idx = NULL, rt_idx = NULL, response_idx = NULL,
                   truth_idx = NULL, response_upper = NULL,
                   stvals = NULL, err_tol = 1e-6) {

  # Format data for fitting
  if (all(is.null(id_idx), is.null(rt_idx), is.null(response_idx),
      is.null(truth_idx), is.null(response_upper))) {
    df <- data # assume input data is already formatted
  } else {
    nr <- nrow(data)
    df <- data.frame(id = character(nr),
                     rt = double(nr),
                     response = integer(nr),
                     rresponse = character(nr),
                     truth = integer(nr),
                     stringsAsFactors = FALSE)

    if (!is.null(id_idx)) { # relabel identification tags
      for (i in 1:length(id_idx)) {
        idi <- unique(data[,id_idx[i]])
        for (j in 1:length(idi)) {
          df$id[data[,id_idx[i]] == idi[j]] <- paste(df$id[data[,id_idx[i]] == idi[j]], idi[j], sep = " ")
        }
      }
      df$id <- trimws(df$id, which = "left")
    }

    df$rt <- as.double(data[,rt_idx])

    df$response <- as.integer(0)
    df$response[data[,response_idx] == response_upper] <- as.integer(1)
    df$rresponse <- "lower"
    df$rresponse[data[,response_idx] == response_upper] <- "upper"

    df$truth <- as.integer(0)
    df$truth[data[,truth_idx] == response_upper] <- as.integer(1)
  }

  # Preliminaries
  df <- subset(df, rt >= 0) # remove any respnose times below 0
  ids <- unique(df$id)
  nids <- max(length(ids), 1) # if inds is null, there is only one individual

  if (is.null(stvals)) {
    # starting value for t0 must be smaller than the smallest rt
    min_rt <- min(df$rt)
    t0_lo <- 0.01*min_rt
    t0_me <- 0.50*min_rt
    t0_hi <- 0.99*min_rt
    stvals <- list(#    v1, v0,   a,    t0,    w, sv
                   list( 0,  0,   1, t0_me,  0.5,  1), # defaults
                   list( 5, -5,   1, t0_me,  0.5,  1), # vary v1 & v0
                   list(-1,  1,   1, t0_me,  0.5,  1), # vary v1 & v0
                   list( 0,  0, 0.5, t0_me,  0.5,  1), # vary a; see KE 5
                   list( 0,  0,   4, t0_me,  0.5,  1), # vary a
                   list( 0,  0,   1, t0_lo,  0.5,  1), # vary t0 !!! .00392 - .00467
                   list( 0,  0,   1, t0_hi,  0.5,  1), # vary t0
                   list( 0,  0,   1, t0_me,  0.2,  1), # vary w
                   list( 0,  0,   1, t0_me,  0.8,  1), # vary w
                   list( 0,  0,   1, t0_me,  0.5,  0.05), # vary sv
                   list( 0,  0,   1, t0_me,  0.5,  5)  # vary sv
              )
  }
  nstvals <- length(stvals)
  stvals_mat <- matrix(unlist(stvals), ncol = max(lengths(stvals)),
                       nrow = nstvals, byrow = TRUE)

  algo_names <- c(rep("fs_Fos_17", nstvals),
                  rep("fs_Kes_17", nstvals), rep("fs_Nav_17", nstvals),
                  rep("fb_Kes_17", nstvals), rep("fb_Nav_17", nstvals),
                  rep("rtdists", nstvals))
  nalgos <- length(unique(algo_names))
  ni <- nalgos*nstvals

  # Initilize the result dataframe
  cnames <- c("id", "Algorithm",
              "init_v1", "init_v0", "init_a", "init_t0", "init_w", "init_sv",
              "fit_v1", "fit_v0", "fit_a", "fit_t0", "fit_w", "fit_sv")
  res <- data.frame(matrix(ncol = length(cnames), nrow = nids*nstvals*nalgos))
  colnames(res) <- cnames

  # Fill in known values
  res[,2] <- algo_names # label algorithms
  res[,3] <- stvals_mat[,1] # label initial v1
  res[,4] <- stvals_mat[,2] # label initial v0
  res[,5] <- stvals_mat[,3] # label initial a
  res[,6] <- stvals_mat[,4] # label initial t0
  res[,7] <- stvals_mat[,5] # label initial w
  res[,8] <- stvals_mat[,6] # label initial sv

  # Loop through each individual and starting values
  for (i in 1:nids) {
    dfi <- subset(df, id == ids[i])
    res[((i-1)*ni+1):(i*ni), 1] <- ids[i] # label individuals
    rti <- dfi$rt
    respi <- dfi$response
    rrespi <- dfi$rresponse
    truthi <- dfi$truth
    for (j in 1:nstvals) {
      temp <- nlminb(stvals[[j]], ll_fs_Fos_17,
                     rt = rti, resp = respi, truth = truthi, err_tol = err_tol,
                     # limits:   v1,   v0,   a,  t0, w,  sv
                     lower = c(-Inf, -Inf,   0,   0, 0,   0),
                     upper = c( Inf,  Inf, Inf, Inf, 1, Inf))
      res[(i-1)*ni+0*nstvals+j, 9:14] <- temp$par

      temp <- nlminb(stvals[[j]], ll_fs_Kes_17,
                     rt = rti, resp = respi, truth = truthi, err_tol = err_tol,
                     # limits:   v1,   v0,   a,  t0, w,  sv
                     lower = c(-Inf, -Inf,   0,   0, 0,   0),
                     upper = c( Inf,  Inf, Inf, Inf, 1, Inf))
      res[(i-1)*ni+1*nstvals+j, 9:14] <- temp$par

      temp <- nlminb(stvals[[j]], ll_fs_Nav_17,
                     rt = rti, resp = respi, truth = truthi, err_tol = err_tol,
                     # limits:   v1,   v0,   a,  t0, w,  sv
                     lower = c(-Inf, -Inf,   0,   0, 0,   0),
                     upper = c( Inf,  Inf, Inf, Inf, 1, Inf))
      res[(i-1)*ni+2*nstvals+j, 9:14] <- temp$par

      temp <- nlminb(stvals[[j]], ll_fb_Kes_17,
                     rt = rti, resp = respi, truth = truthi, err_tol = err_tol,
                     # limits:   v1,   v0,   a,  t0, w,  sv
                     lower = c(-Inf, -Inf,   0,   0, 0,   0),
                     upper = c( Inf,  Inf, Inf, Inf, 1, Inf))
      res[(i-1)*ni+3*nstvals+j, 9:14] <- temp$par

      temp <- nlminb(stvals[[j]], ll_fb_Nav_17,
                     rt = rti, resp = respi, truth = truthi, err_tol = err_tol,
                     # limits:   v1,   v0,   a,  t0, w,  sv
                     lower = c(-Inf, -Inf,   0,   0, 0,   0),
                     upper = c( Inf,  Inf, Inf, Inf, 1, Inf))
      res[(i-1)*ni+4*nstvals+j, 9:14] <- temp$par

      temp <- nlminb(stvals[[j]], ll_RTDists,
                     rt = rti, resp = rrespi, truth = truthi,
                     # limits:   v1,   v0,   a,  t0, w,  sv
                     lower = c(-Inf, -Inf,   0,   0, 0,   0),
                     upper = c( Inf,  Inf, Inf, Inf, 1, Inf))
      res[(i-1)*ni+5*nstvals+j, 9:14] <- temp$par
    }
  }
  return(res)
}
```



### Running the Fitting {#fit-run}
Having set up the fitting functions in the above chunks of code, we run and save the fitting here. However, this takes a long time so we will read the pre-fit parameter estimates in the subsequent code chunk.
```{r fitting-run, eval=FALSE}
data(med_dec, package = "fddm")
data <- subset(med_dec, id %in% unique(med_dec$id)[2] & group %in% unique(med_dec$group)[1])
fit <- rt_fit(data, id_idx = c(2,1), rt_idx = 8, response_idx = 7,
              truth_idx = 5, response_upper = "blast", err_tol = 1e-6)
```

```{r fitting-read, eval=TRUE}
saveRDS(fit, file = "inst/extdata/test-fitting-fit1.Rds")
fit <- readRDS(system.file("extdata", "test-fitting-fit.Rds", package = "fddm", mustWork = TRUE))
```



## Testing the Fitted Parameters {#fit-test}
Now we test the consistency of the fitted parameters using the various density function approximations by using the `testthat` package. As [discussed above](#fit), we use an allowable tolerance of 0.0001 to account for the slight differences in the output of the different approximations. We initially compare the fitted parameter values produced from one method across all starting points to ensure local minima have been avoided. Upon confirming that the method yields the same fitted parameters, we use the mean parameter for each method to compare the fitting results across the methods. If all tests pass correctly, there should be no output.
```{r fitting-test, eval=TRUE}
library("testthat")

# Define error tolerance
eps <- 1e-4

# Calculate differences and means
nr <- nrow(fit)
fit$v1_dif <- rep(0, nr)
fit$v0_dif <- rep(0, nr)
fit$a_dif  <- rep(0, nr)
fit$t0_dif <- rep(0, nr)
fit$w_dif  <- rep(0, nr)
fit$sv_dif <- rep(0, nr)

inds <- unique(fit$ind)
ninds <- length(inds)
algos <- unique(fit$Algorithm)
nalgos <- length(algos)

cnames <- c('ind', 'Algorithm', 'v1_avg', 'v0_avg',
            'a_avg', 't0_avg', 'w_avg', 'sv_avg')
avg_df <- data.frame(matrix(ncol = length(cnames), nrow = ninds*nalgos))
colnames(avg_df) <- cnames
avg_df$Algorithm <- rep(algos, ninds)

start <- 1
stop <- nrow(subset(fit, ind == inds[1] & Algorithm == algos[1]))
for (i in 1:ninds) {
  avg_df$ind[((i-1)*nalgos+1):(i*nalgos)] <- rep(inds[i], nalgos) # label ind
  for (j in 1:nalgos) {
    if (j == 3) { # Navarro_s, see KE 6
      tmp_fits <- subset(fit, ind == inds[i] & Algorithm == algos[j] & init_a > 0.9)[, 9:14]
    } else{
      tmp_fits <- subset(fit, ind == inds[i] & Algorithm == algos[j])[, 9:14]
    }
    avg_df[(i-1)*nalgos+j,3:8] <- colMeans(tmp_fits) # collect means
    for (k in 1:(stop-1)) {
      fit[start+k, 15:20] <- abs(fit[start, 9:14] - fit[(start+k), 9:14])
    }
    start = start + stop
  }
}


# Subset
Foster <- subset(fit, Algorithm == "fs_Fos_17")
Kesselmeier_s <- subset(fit, Algorithm == "fs_Kes_17")
Navarro_s <- subset(fit, Algorithm == "fs_Nav_17" & init_a > 0.9) # see KE 6
Kesselmeier_b <- subset(fit, Algorithm == "fb_Kes_17")
Navarro_b <- subset(fit, Algorithm == "fb_Nav_17")
rtdists <- subset(fit, Algorithm == "rtdists")

Foster_avg <- subset(avg_df, Algorithm == "fs_Fos_17")
Kesselmeier_s_avg <- subset(avg_df, Algorithm == "fs_Kes_17")
Navarro_s_avg <- subset(avg_df, Algorithm == "fs_Nav_17")
Kesselmeier_b_avg <- subset(avg_df, Algorithm == "fb_Kes_17")
Navarro_b_avg <- subset(avg_df, Algorithm == "fb_Nav_17")
rtdists_avg <- subset(avg_df, Algorithm == "rtdists")


# Test accuracy for fitted parameters: v_upper, v_lower, a, w
test_that("Consistency within each method, using different starting values", {
  expect_true(all(Foster[,15:20] < eps))
  expect_true(all(Kesselmeier_s[,15:20] < eps))
  expect_true(all(Navarro_s[,15:20] < eps))
  expect_true(all(Kesselmeier_b[,15:20] < eps))
  expect_true(all(Navarro_b[,15:20] < eps))
  expect_true(all(rtdists[,15:20] < eps))
})

test_that("Accuracy across different methods", {
  expect_true(all(abs(Foster_avg[,-(1:2)] - Kesselmeier_s_avg[,-(1:2)]) < eps))
  expect_true(all(abs(Foster_avg[,-(1:2)] - Navarro_s_avg[,-(1:2)]) < eps))
  expect_true(all(abs(Foster_avg[,-(1:2)] - Kesselmeier_b_avg[,-(1:2)]) < eps))
  expect_true(all(abs(Foster_avg[,-(1:2)] - Navarro_b_avg[,-(1:2)]) < eps))
  expect_true(all(abs(Foster_avg[,-(1:2)] - rtdists_avg[,-(1:2)]) < eps))
})

```



## Known Errors {#fit-ke}

5) If the two starting parameter values for the drift rates are precisely $v_1 = 5$ and $v_0 = -5$, then the optimization using Foster small-time approximation gets stuck and hangs.

6) If the starting parameter value for $a \leq 0.9$ then the Navarro small-time approximation yields wildly inaccurate parameter estimates for all of the parameters.





</div>
#  {.unlisted .unnumbered}
#### R Session Info {.unlisted .unnumbered}
```{r session-info, collapse=TRUE}
sessionInfo()
```



# References {.unlisted .unnumbered}
